# DeepDream 项目
## 概述
    - google公司推出
    - 与CNN应用的差别
        - cnn图像分类
            - 数据集经过卷积神经网络，形成预测结果；
            - 用预测结果与真实标签比较
            - 返回头调整卷积神经网络的参数（以及全连接层参数）
            - 如此反复得到最终模型
        - deep dream技术原理
            - 输入数据。数据可以是噪音，也可以是图像
            - 经过卷积神经网络（和全连接层），形成预测结果
            - 指定一个标签（比如当想要生成海星状图像时，把目标标签指定为“海星”）
            - 通过将目标标签与预测结果比较，将两者的误差反向传递到输入图像，并以此来调整输入图像的像素值
        - 主要差异：
            - cnn是将预测结果与真实标签比较后，根据误差调整卷积神经网的参数值(w和b)
            - deepDream技术是将预测结果与指定标签比较后，根据误差调整调整输入图像的像素值

## 经典卷积神经网络：AlexNet
    - 数据增强：
        - 深度学习需要拥有足够的训练样本。通常样本量越大，训练的模型效果越好
        - 在图像任务中，对输入图像进行一些简单的平移、翻转、缩放、颜色变换，并不会影响图像的类别。例如，水平翻转后的狗的图像，它的类别当然还是犬类
        - 所以，利用平移、缩放、颜色变换等，可以人工增大训练集的样本个数，从而获得更充足的训练集，使模型训练效果更好

    - 图像编码和解码函数
        - RGB图像可以看作一个三维矩阵，矩阵中每个数表示了图像上不同位置、不同颜色的亮度。图像存储时不是直接记录这些数字，而是记录经过压缩编码之后的结果。所以要将一张图像还原成一个三维矩阵，需要进行解码。tensorflow提供了jpg和png图像的编码和解码函数
    - 图像缩放
    - 图像的裁剪和填充
    - 图像的水平和上下翻转
    - 改变对比度
    - 白化处理：又称标准化/归一化处理，即将图像的像素值转换为零均值和单位方差

## 防止过拟合的方法：dropout
    - 用于全连接层
    - 每次迭代时，以某概率将神经元输出置零，不参与前向和后向传播
    - 因此每次迭代都会产生不同的网络结构。将不同结构进行组合，大大减少了过拟合
    - 缺点：收敛所需的迭代次数增加大约1倍左右，从而训练时间增加

## 激活函数
    - 在deepdream中，用非线性激活函数relu函数替代了sigmoid

## 经典卷积神经网络：VGGNet
    - 可以看成加深版的AlexNet
    - 分5个卷积组
    - 网络深度：11-19层
    - 卷积核尺寸3*3
    - 卷积核深度：大部分采用了逐层递增的方式
    - VGG16和VGG19应用最广泛
    - 随着网络深度的加深，准确率的提升也到了瓶颈，所以VGGNet没有继续提出19向后（VGG20,VGG30）的深度

## 经典卷积神经网络：GoogleNet

## 经典卷积神经网络：ResNet
    - 将VGGnet和GoogleNet结合，深度达到152层
    - ResNet的shortcut结构能够避免网络的退化（即传统的CNN随着网络深度的增加会出现训练误差和测试误差增大的情况）和梯度消失/爆炸现象，使得ResNet能够从网络层数的加深中受益，这也是为什么ResNet 能够做到34层，50层，甚至152层，甚至是1202层的缘故

## tensorflow模型训练社区Model Zoo
